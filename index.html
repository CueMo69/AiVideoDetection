<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Video Detection</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>AI Video Detection</h1>
    </header>
    <div id="container">
        <video id="video" autoplay></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="output"></div>
    <div id="spinner">
        <img src="spinner.gif" alt="Loading...">
    </div>
    <button id="toggleButton">Stop Detection</button>
    <button id="flipButton">Flip Camera</button>
    <div class="footer">
        <p>Powered by TensorFlow.js and COCO-SSD | Created by CueMo69</p>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const output = document.getElementById('output');
        const spinner = document.getElementById('spinner');
        const toggleButton = document.getElementById('toggleButton');
        const flipButton = document.getElementById('flipButton');
        let model;
        let detect = true;

        toggleButton.addEventListener('click', () => {
            detect = !detect;
            toggleButton.innerText = detect ? 'Stop Detection' : 'Start Detection';
            if (detect) {
                detectFrame(video, model);
            }
        });

        flipButton.addEventListener('click', () => {
            video.classList.toggle('flip');
        });

        // Load the COCO-SSD model
        cocoSsd.load().then(loadedModel => {
            model = loadedModel;
            // Start the video stream
            navigator.mediaDevices.getUserMedia({
                video: true
            }).then(stream => {
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    detectFrame(video, model);
                };
            }).catch(error => {
                console.error("Error accessing webcam:", error);
            });
        });

        // Detect objects in the video frame
        function detectFrame(video, model) {
            if (detect) {
                model.detect(video).then(predictions => {
                    renderPredictions(predictions);
                    requestAnimationFrame(() => {
                        detectFrame(video, model);
                    });
                });
            }
        }

        // Render the predictions on the video feed
        function renderPredictions(predictions) {
            context.clearRect(0, 0, canvas.width, canvas.height);
            output.innerHTML = '';
            predictions.forEach(prediction => {
                // Draw bounding box
                context.beginPath();
                context.rect(...prediction.bbox);
                context.lineWidth = 2;
                context.strokeStyle = 'red';
                context.fillStyle = 'red';
                context.stroke();
                context.fillText(
                    `${prediction.class} - ${Math.round(prediction.score * 100)}%`,
                    prediction.bbox[0],
                    prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
                );
                context.fill();
                // Display prediction
                const p = document.createElement('p');
                p.innerText = `${prediction.class} - ${Math.round(prediction.score * 100)}%`;
                output.appendChild(p);
            });
        }
    </script>
</body>
</html>
